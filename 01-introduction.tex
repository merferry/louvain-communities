Community detection\ignore{, also know as clustering,} is the problem of uncovering the underlying structure of complex networks, i.e., identifying groups of vertices that exhibit dense internal connections but sparse connections with the rest of the network, in an unsupervised manner. It is an NP-hard problem with numerous applications in domains such as drug discovery, protein annotation, topic discovery, anomaly detection, and criminal identification. Communities identified are intrinsic when based on network topology alone, and are disjoint when each vertex belongs to only one community \cite{com-gregory10}.\ignore{One of the difficulties in the community detection problem is the lack of apriori knowledge on the number and size distribution of communities \cite{com-blondel08}.} The \textit{Louvain} method \cite{com-blondel08} is a popular heuristic-based approach for community detection, with the modularity metric \cite{com-newman06} being used to measure the quality of communities identified.

In recent years, the collection of data and the relationships among them, represented as graphs, have reached unmatched levels. This has necessitated the design of efficient parallel algorithms for community detection on large networks. The multicore/shared memory setting is crucial for community detection due to its energy efficiency and the prevalence of hardware with extensive DRAM sizes.\ignore{Optimizing parallel community detection algorithms for modern hardware architectures can yield notable performance benefits and competitive advantages across applications.} However, many of the current algorithms for community detection are challenging to parallelize due to their irregular and inherently sequential nature \cite{com-halappanavar17}, in addition to the complexities of handling concurrency, optimizing data access, reducing contention, minimizing load imbalance.

In recent years, significant research effort has focused on developing efficient parallel implementations of PageRank for multicore CPUs \cite{staudt2015engineering, staudt2016networkit, com-fazlali17, com-halappanavar17, qie2022isolate}, GPUs \cite{com-naim17}, CPU-GPU hybrids \cite{com-bhowmik19, com-mohammadi20}, multi-GPUs \cite{com-cheong13, hricik2020using, chou2022batched, com-gawande22}, and multi-node systems --- CPU only \cite{com-ghosh18, ghosh2018scalable, sattar2022scalable} / CPU-GPU hybrids \cite{com-bhowmick22}. Also there has been a tremendous focus of a variety of algorithmic techniques, but not on the use of suitable data structures for use with Louvain algorithm. Existing studies on Louvain propose a number of algorithmic optimizations \cite{com-rotta11, com-waltman13, com-gach14, com-traag15, com-lu15, com-ryu16, com-ozaki16, com-naim17, com-halappanavar17, com-ghosh18, com-traag19, com-zhang21, com-shi21, com-you22, com-aldabobi22} and parallelization techniques \cite{com-cheong13, com-wickramaarachchi14, com-lu15, com-zeng15, com-que15, com-naim17, com-fazlali17, com-halappanavar17, com-zeitz17, com-ghosh18, com-bhowmik19, com-gheibi20, com-shi21, com-bhowmick22}, but do not address optimization for the aggregation phase of the Louvain algorithm, which emerges as a bottleneck after the local-moving phase of the algorithm has been optimized. Moreover, these optimization techniques are scattered over a number of papers, making it difficult for a reader to get a grip over them.

Unfortunately, many of the researches have focused entirely on the GPUs, while the prices of GPUs have continue to skyrocket. Further, developing algorithms that make efficient use of the GPU are difficult to write, and maintain. Further, we observe that researchers tend to develop a different mindset when developing algorithms for the GPU, which does not carry forward to the CPU. From this implementation of the Louvain algorithm, we hope to show that CPUs continue to excel at irregular computation, particularly for algorithms, where the workload continues to decrease as the iterations progress. We show that achieving good performance requires a greater focus on the data structures being used, rather than on the algorithmic techniques (note that algorithms build around the data structures). We observe that some studies do not properly parallelize the algorithm with OpenMP. This results is them being able to show greater speedup for the CPU, with respect to CPU.

In this technical report, we introduce our parallel multicore implementation of the Louvain algorithm\footnote{https://github.com/puzzlef/louvain-communities-openmp}. Our implementation employs asynchronous computation, utilizing parallel prefix sum and preallocated Compressed Sparse Row (CSR) data structures for identifying community vertices and storing the super-vertex graph during the aggregation phase. We utilize fast collision-free per-thread hash tables, notably \textit{Far-KV}, for the local-moving and aggregation phases, while incorporating an aggregation tolerance to avoid unnecessary aggregation phases. Additionally, we leverage established techniques such as OpenMP's \verb|dynamic| loop schedule, iteration limiting per pass, threshold-scaling optimization, and vertex pruning to determine optimal parameter settings.

To the best of our knowledge, our implementation represents the most efficient parallel Louvain algorithm implementation on multicore CPUs. We compare our implementation against other state-of-the-art implementations, including multi-core, multi-node, hybrid GPU, multi-GPU, and multi-node multi-GPU implementations, in Table \ref{tab:compare}. Both direct and indirect comparisons are provided, with details given in Sections \ref{sec:comparison} and \ref{sec:comparison-indirect} respectively.

% In this paper, we present our multicore CPU implementation of the Louvain algorithm,\footnote{https://github.com/puzzlef/louvain-communities-openmp} which utilizes an asynchronous computation that makes use of parallel prefix sum and preallocated Compressed Sparse Row (CSR) data structures for finding community vertices and for storing the super-vertex graph during the aggregation phase, uses fast collision-free per-thread hashtables which are well separated in their memory addresses (\textit{Far-KV}) for the local-moving and aggregation phases of the algorithm, avoids unnecessary aggregation phases with an aggregation tolerance. In addition, it uses well known techniques, such as, using OpenMP's \verb|dynamic| loop schedule, limiting the number of iterations per pass, using the threshold-scaling optimization, and employing vertex pruning, while determining suitable parameter settings.

Our implementation represents, to the best of our knowledge, the most efficient implementation for parallel Louvain algorithm on multicore CPUs. Our multicore CPU implementation of Louvain algorithm is compared with other state-of-the-art implementations, including multi-core, multi-node, hybrid GPU, multi-GPU, and multi-node multi-GPU implementations, in Table \ref{tab:compare}. It includes both direct and indirect comparisons, with details given in Sections \ref{sec:comparison} and \ref{sec:comparison-indirect} respectively.

%% NOTE: Vite is ghosh18scalable

\input{src/tab-compare}




\ignore{\subsection{Our Contributions}}

\ignore{This report introduces GVE-Louvain, an optimized parallel implementation of Louvain\footnote{https://github.com/puzzlef/louvain-communities-openmp} for shared memory multicores. On a machine with two 16-core Intel Xeon Gold 6226R processors, GVE-Louvain outperforms Vite, Grappolo, and NetworKit Louvain by $50\times$, $22\times$, and $20\times$ respectively, achieving a processing rate of $560 M$ edges/s on a $3.8 B$ edge graph. With doubling of threads, GVE-Louvain exhibits an average performance scaling of $1.6\times$.}




%% - Use --- for a dash.
%% - Use ``camera-ready'' for quotes.
%% - Use {\itshape very} or \textit{very} for italicized text.
%% - Use \verb|acmart| or {\verb|acmart|} for mono-spaced text.
%% - Use \url{https://capitalizemytitle.com/} for URLs.
%% - Use {\bfseries Do not modify this document.} for important boldface details.
%% - Use \ref{fig:name} for referencing.

%% For a block of pre-formatted text: 
% \begin{verbatim}
%   \renewcommand{\shortauthors}{McCartney, et al.}
% \end{verbatim}

%% For a list of items:
% \begin{itemize}
% \item the ``ACM Reference Format'' text on the first page.
% \item the ``rights management'' text on the first page.
% \item the conference information in the page header(s).
% \end{itemize}

%% For a table:
% \begin{table}
%   \caption{Frequency of Special Characters}
%   \label{tab:freq}
%   \begin{tabular}{ccl}
%     \toprule
%     Non-English or Math&Frequency&Comments\\
%     \midrule
%     \O & 1 in 1,000& For Swedish names\\
%     $\pi$ & 1 in 5& Common in math\\
%     \$ & 4 in 5 & Used in business\\
%     $\Psi^2_1$ & 1 in 40,000& Unexplained usage\\
%   \bottomrule
% \end{tabular}
% \end{table}

%% For a full-width table:
% \begin{table*}
%   \caption{Some Typical Commands}
%   \label{tab:commands}
%   \begin{tabular}{ccl}
%     \toprule
%     Command &A Number & Comments\\
%     \midrule
%     \texttt{{\char'134}author} & 100& Author \\
%     \texttt{{\char'134}table}& 300 & For tables\\
%     \texttt{{\char'134}table*}& 400& For wider tables\\
%     \bottomrule
%   \end{tabular}
% \end{table*}


%% For inline math:
% \begin{math}
%   \lim_{n\rightarrow \infty}x=0
% \end{math},

%% For a numbered equation:
% \begin{equation}
%   \lim_{n\rightarrow \infty}x=0
% \end{equation}

%% For an unnumbered equation:
% \begin{displaymath}
%   \sum_{i=0}^{\infty} x + 1
% \end{displaymath}

%% For a figure:
% \begin{figure}[h]
%   \centering
%   \includegraphics[width=\linewidth]{inc/sample-franklin}
%   \caption{1907 Franklin Model D roadster. Photograph by Harris \&
%     Ewing, Inc. [Public domain], via Wikimedia
%     Commons. (\url{https://goo.gl/VLCRBB}).}
%   \Description{A woman and a girl in white dresses sit in an open car.}
% \end{figure}

%% For a teaser figure.
% \begin{teaserfigure}
%   \includegraphics[width=\textwidth]{sampleteaser}
%   \caption{figure caption}
%   \Description{figure description}
% \end{teaserfigure}
