\subsection{Experimental Setup}
\label{sec:setup}

We use a server that has two $16$-core x86-based Intel Xeon Gold 6226R processors running at $2.90$ GHz. Each core has an L1 cache of $1$ MB, an L2 cache of $16$ MB, and a shared L3 cache of $22$ MB. The machine has $93.4$ GB of system memory and runs on CentOS Stream 8. We use GCC 8.5 and OpenMP 4.5. Table \ref{tab:dataset} shows the graphs we use in our experiments. All of them are obtained from the SuiteSparse Matrix Collection \cite{suite19}.

\input{src/tab-dataset}
\input{src/fig-louvain-compare}
\input{src/fig-louvain-compares}
\input{src/fig-louvain-ss}




\subsection{Comparing Performance of GVE-Louvain}

We now compare the performance of GVE-Louvain with Vite (Louvain), Grappolo (Louvain), and NetworKit Louvain. For Vite, we convert the graph datasets to Vite's binary graph format, run it on a single node (Vite supports distributed community detection) with threshold cycling/scaling optimization, and measure the reported average total time. For Grappolo, we measure the run it on the same system, and measure the reported total time. For NetworKit, we use a Python script to invoke \texttt{PLM} (Parallel Louvain Method), and measure the total time reported with \texttt{getTiming()}. For each graph, we measure the runtime of each implementation five times, for averaging. We also record the modularity of communities obtained, as reported by each implementation.

Figure \ref{fig:louvain-compare} shows the runtimes of Vite (Louvain), Grappolo (Louvain), NetworKit Louvain, and GVE-Louvain on each graph in the dataset. Figure \ref{fig:louvain-compares} shows the speedup of GVE-Louvain with respect to each implementation mentioned above. GVE-Louvain is on average $50\times$, $22\times$, and $20\times$ faster than Vite, Grappolo, and NetworKit respectively. On the \textit{sk-2005} graph, GVE-Louvain finds communities in $6.8$ seconds, and thus achieve a processing rate of $560$ million edges/s. Figure \ref{fig:louvain-compare} also shows the modularity of communities obtained with each implementation on the secondary (right) Y-axis. GVE-Louvain on average obtains $3.1\%$ higher modularity than Vite (especially on web graph), and $0.6\%$ lower modularity than Grappolo and NetworKit (especially on social networks with poor clustering).

\input{src/fig-louvain-hardness}
\input{src/fig-louvain-splits}




\subsection{Results with our optimized implementation}

The combined optimizations yield impressive performance improvements in the OpenMP-based \StaLou{}, with a completion time of $6.8$ seconds on the \textit{sk-2005} graph containing $3.8 B$ edges (refer to Figure \ref{fig:louvainrak-sta}). We observe that graphs with lower average degree (\textit{road networks} and \textit{protein k-mer graphs}) and graphs with poor community structure (such as \verb|com-LiveJournal| and \verb|com-Orkut|) have a larger $\text{runtime}/|E|$ factor, as shown in Figure \ref{fig:louvainrak-hardness--louvain}.

The phase-wise and pass-wise split of the optimized \StaLou{} is shown in Figure \ref{fig:louvain-splits}. Note how $48\%$ (most) of the runtime of the algorithm is spent in the local-moving phase, while only $29\%$ of the runtime is spent in the aggregation phase of the algorithm. Further, $68\%$ (most) of the runtime is spent in the first pass of the algorithm, which is the most expensive pass due to the size of the original graph (later passes work on super-vertex graphs) \cite{com-wickramaarachchi14}.




\subsection{Strong Scaling of GVECD}

Finally, we measure the strong scaling performance of our Louvain and LPA. To this end, we adjust the number of thread from $1$ to $64$ in multiples of $2$ for each input graph, and measure the time taken for finding communities within each graph with our Louvain and LPA. As for each experiment above, for each graph, and for each thread count, we perform our Louvain and LPA five times for averaging. The results are shown in Figure \ref{fig:louvainrak-ss}. With 32 threads, finding communities with our Louvain obtains a $10.4\times$ speedup compared to running with a single thread, i.e., the performance of our Louvain increases by $1.6\times$ for every doubling of threads. Further, with 32 threads, finding communities with our LPA obtains a speedup of $13.5\times$ with respect to a single threaded execution, i.e., our LPA's performance increases by $1.7\times$ for every doubling of threads. Our LPA is thus more scalable than our Louvain due to its algorithmic simplicity (one only phase, in contrast to Louvain which has both a local-moving and an aggregation phase along with an expensive initialization step). At 64 threads, both our Louvain and our LPA are impacted by NUMA effects, and offer speedups of only $11.4\times$ and $18.1\times$ respectively. Note that our Louvain is significantly affected due to the reasons mentioned above.
