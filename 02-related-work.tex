The \textit{Louvain} method is a greedy modularity-optimization based community detection algorithm, and is introduced by Blondel et al. from the University of Louvain \cite{com-blondel08}. It identifies communities with resulting high modularity, and is thus widely favored \cite{com-lancichinetti09}. Algorithmic improvements proposed for the original algorithm include early pruning of non-promising candidates (leaf vertices) \cite{com-ryu16, com-halappanavar17, com-zhang21, com-you22}, attempting local move only on likely vertices \cite{com-ryu16, com-ozaki16, com-zhang21, com-shi21}, ordering of vertices based on node importance \cite{com-aldabobi22}, moving nodes to a random neighbor community \cite{com-traag15}, threshold scaling \cite{com-lu15, com-naim17, com-halappanavar17}, threshold cycling \cite{com-ghosh18}, subnetwork refinement \cite{com-waltman13, com-traag19}, multilevel refinement \cite{com-rotta11, com-gach14, com-shi21}, and early termination \cite{com-ghosh18}.

To parallelize the Louvain algorithm, a number of strategies have been attempted. These include using heuristics to break the sequential barrier \cite{com-lu15}, ordering vertices via graph coloring \cite{com-halappanavar17}, performing iterations asynchronously \cite{com-que15, com-shi21}, using adaptive parallel thread assignment \cite{com-fazlali17, com-naim17, com-sattar19, com-mohammadi20}, parallelizing the costly first iteration \cite{com-wickramaarachchi14}, using vector based hashtables \cite{com-halappanavar17}, and using sort-reduce instead of hashing \cite{com-cheong13}\ignore{, using simple partitions based of vertex ids \cite{com-cheong13, com-ghosh18}, and identifying and moving ghost/doubtful vertices \cite{com-zeng15, com-que15, com-bhowmik19, com-bhowmick22}}. Platforms used range from an AMD multicore system \cite{com-fazlali17}, and Intelâ€™s Knight's Landing, Haswell \cite{com-gheibi20}, SkylakeX, and Cascade Lake \cite{part-hossain21}. Other approaches include the use of MapReduce in a BigData batch processing framework \cite{com-zeitz17}. It should however be noted though that community detection methods such as the Louvain that rely on modularity maximization are known to suffer from resolution limit problem. This prevents identification of communities of certain sizes \cite{com-ghosh19}.

A few open source implementations and software packages have been developed for community detection. Vite \cite{ghosh2018scalable} is a distributed memory parallel implementation of the Louvain method that incorporates several heuristics to enhance performance while maintaining solution quality, while Grappolo \cite{com-halappanavar17} is a shared memory parallel implementation. NetworKit \cite{staudt2016networkit} is a software package designed for analyzing the structural aspects of graph data sets with billions of connections. It is implemented as a hybrid with C++ kernels and a Python frontend, and includes a parallel implementation of the Louvain algorithm.

%%

Mohammadi et al. \cite{com-mohammadi20} propose the Adaptive CUDA Louvain Method (ACLM), employing GPU acceleration. Their approach involves evaluating the change in modularity for each edge in the graph, reflecting the impact of moving the source vertex to the community of the target vertex. Notably, only the computation of modularity changes occurs on the GPU, with other algorithmic steps executed on the CPU. Sattar and Arifuzzaman \cite{sattar2022scalable} discuss their Distributed Parallel Louvain Algorithm with Load-balancing (DPLAL). They begin by partitioning the input graph using METIS, employing the edge-cut partitioning approach. In each iteration, they determine the optimal community to relocate to for each vertex, execute community changes while tackling duality concerns, evaluate the new modularity, and generate the subsequent level graph. This iterative process continues until no further enhancement in modularity is achieved. Nonetheless, they conduct only a single iteration of the local-moving phase per iteration, which might result in the identification of substandard quality communities.\ignore{It is not clear if they perform local-moves to the best community per vertex, or just any community with a positive delta-modularity score. They do not present the quality of returned communities.} Qie et al. \cite{qie2022isolate} present a graph partitioning algorithm that divides the graph into sets of partitions, aiming to minimize inter-partition communication delay and avoid community swaps, akin to the graph coloring approach proposed by Halappanavar et al. \cite{com-halappanavar17}. We do not observe community swap issue on CPUs (it likely resolves itself), but do observe it on GPUs (likely due to lockstep execution). Bhowmick et al. \cite{com-bhowmik19} introduce HyDetect, a community detection algorithm designed for hybrid CPU-GPU systems, employing a divide-and-conquer strategy. The algorithm partitions the graph among the CPU and GPU components of a node, facilitating independent community detection utilizing the Louvain algorithm in both segments. Bhowmick et al. \cite{com-bhowmick22} later introduce a multi-node multi-GPU Louvain community detection algorithm, which involves graph partitioning across multiple nodes, refinement through identification and migration of doubtful vertices between processors, and utilization of a hierarchical merging algorithm ensuring that the merged components can be accommodated within a processor at any given point. Chou and Ghosh \cite{chou2022batched} present Nido, a batched clustering method for GPUs that leverages a partition-based design, and can process graphs larger than the combined GPU memory of a node. Gawande et al. \cite{com-gawande22} propose cuVite, an ongoing endeavor focusing on distributed Louvain for heterogeneous systems --- building upon their previous work involving parallelizing the Louvain method for community detection on CPU-only distributed systems.

Problems with NetworKit Louvain:
- It uses plain OpenMP parallel for certain operations (static schedule, chunk size 1). This is not optimal if threads are writing to adjacent memory addresses. We use a chunk size of 2048.
- It uses guided scheduling for the local-moving phase. This may not be optimal. We use dynamic scheduling.
- It only times the local-moving and aggregation phase. This is more conservative than expected. Thus, our implementation is actually even more faster than NetworKit Louvain.
- It generates a new graph for each coarsening step, upon with NetworKit Louvain is run recursively. This is not good for performance, as a fresh memory is being allocated for each coarsened graph, and the recursive calls result in repeated preprocessing and memory allocation. Also the coarsening has a number of sequential operations. Adding each edge to the coarsened graph is also done using $O(D)$ operations, where $D$ is the average degree of a vertex in the graph. This is not optimal for parallelism.
- For flattening the dendrogram, it does not use a parallel for.
